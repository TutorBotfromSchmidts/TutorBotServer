# MODEL PROVIDER (required)

##  - OPENAI
##  - GOOGLE
##  - IBM
##  - ANTHROPIC (not supported yet)
##  - OLLAMA (not supported yet)

MODEL_PROVIDER=


# MODEL SELECTION (required)

# You can use any of the following models:

## OpenAI
##  - chatgpt-4o-latest (tested)
##  - gpt-4o-mini
##  - o1-preview
##  - o1-mini
##  - gpt-4-turbo
##  - gpt-3.5-turbo

## Google
##  - gemini-1.5-pro (tested)
##  - gemini-1.5-flash

## IBM
##  - ibm/granite-34b-code-instruct (tested)
##  - meta-llama/llama-3-2-90b-vision-instruct (tested)

## Anthropic
##  - claude-3-5-sonnet-latest (tested, not supported yet)

## Ollama
##  - llama3.2 (tested, not supported yet)

MODEL=


# API KEY (required, if using a provider other than Google)
# Enter your API key for the selected model provider
API_KEY=


# GOOGLE_APPLICATION_CREDENTIALS (required, if using Google as provider)
# Set the path to your Google Cloud credentials file (JSON)
GOOGLE_APPLICATION_CREDENTIALS=

# IBM_URL (required, if using IBM as provider)
# Set the URL for the IBM Cloud ML service
IBM_URL=

# IBM_PROJECT_ID (required, if using IBM as provider)
# Set the project ID for the IBM Cloud ML service
IBM_PROJECT_ID=

# MAX_TOKENS (optional)
# Set the maximum number of tokens to generate
MAX_TOKENS=

# MAX_RETRIES (optional)
# Set the maximum number of retries for LLM requests
MAX_RETRIES=

# TIMEOUT (optional)
# Set the timeout for LLM requests
TIMEOUT=

# TEMPERATURE (optional)
# Set the temperature for sampling
TEMPERATURE=

# TOP_P (optional)
# Set the nucleus sampling parameter
TOP_P=

# FREQUENCY_PENALTY (optional)
# Set the frequency penalty parameter
FREQUENCY_PENALTY=

# PRESENCE_PENALTY (optional)
# Set the presence penalty parameter
PRESENCE_PENALTY=
